# Tri-Sense
A hand motion tracking project: MVP test - detect hand position and return words based on hand pose. Hopeful MVP to ship - detect hand position, relate to American Sign Language alphabet, pull words from Merriam-Webster's Dictionary API and provide functionality to sign our words returned as audio and text (can scale back to still provide viable product within the limited timeframe)
## User-Story
**Used primarily by**:<br/>
As a person who is hard of hearing, I want to sign out my words converted to sounds and written form so that I can more efficiently communicate with all other people in a multitude of situations.<br/><br/>
**End user goal**:<br/>
Sign language interpreted by camera and returned as written and vocalized characters.<br/><br/> 
**End business goal**:<br/> Camera access. Oxford Dictionary API.<br/><br/>
**Acceptance criteria**:<br/> Track hand motion and nuances. Refer to American Sign Language Alphabet. Refer to Oxford Dictionary API. Return written characters. Return vocal versions of signed characters.<br/><br/>
![Tri-Sense Mockup](/tri-sense_mockup.png)

Sources: 
MediaPipe documentation and code boilerplate: https://google.github.io/mediapipe/getting_started/javascript.html
General connecting webcam to browser capability: https://www.kirupa.com/html5/accessing_your_webcam_in_html5.htm
General create files via javascript: https://code-boxx.com/create-save-files-javascript/
