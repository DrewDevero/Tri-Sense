# Tri-Sense
A hand motion tracking project: MVP test - detect hand position and return words based on hand pose. Hopeful MVP to ship - detect hand position, relate to American Sign Language alphabet, pull words from Oxford Dictionary API and provide functionality to sign our words returned as audio and text (can scale back to still provide viable product within the limited timeframe)
## User-Story
**Used primarily by**:<br/>
As a person who is hard of hearing, I want to sign out my words converted to sounds and written form so that I can more efficiently communicate with all other people in a multitude of situations.<br/><br/>
**End user goal**:<br/>
Sign language interpreted by camera and returned as written and vocalized characters.<br/><br/> 
**End business goal**:<br/> Camera access. Oxford Dictionary API.<br/><br/>
**Acceptance criteria**:<br/> Track hand motion and nuances. Refer to American Sign Language Alphabet. Refer to Oxford Dictionary API. Return written characters. Return vocal versions of signed characters.